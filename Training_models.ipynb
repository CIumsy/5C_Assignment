{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.26.3)\n",
            "Collecting albumentations\n",
            "  Downloading albumentations-1.4.17-py3-none-any.whl (216 kB)\n",
            "     -------------------------------------- 216.5/216.5 kB 1.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.4.1.post1)\n",
            "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from albumentations) (1.12.0)\n",
            "Collecting scikit-image>=0.21.0\n",
            "  Downloading scikit_image-0.24.0-cp311-cp311-win_amd64.whl (12.8 MB)\n",
            "     --------------------------------------- 12.8/12.8 MB 10.2 MB/s eta 0:00:00\n",
            "Collecting PyYAML\n",
            "  Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
            "Collecting pydantic>=2.7.0\n",
            "  Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "Collecting albucore==0.0.17\n",
            "  Downloading albucore-0.0.17-py3-none-any.whl (10 kB)\n",
            "Collecting eval-type-backport\n",
            "  Downloading eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\n",
            "Collecting opencv-python-headless>=4.9.0.80\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
            "     ---------------------------------------- 38.8/38.8 MB 5.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.3.0)\n",
            "Collecting annotated-types>=0.6.0\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Collecting pydantic-core==2.23.4\n",
            "  Using cached pydantic_core-2.23.4-cp311-none-win_amd64.whl (1.9 MB)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2.7.0->albumentations) (4.10.0)\n",
            "Requirement already satisfied: networkx>=2.8 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (3.2.1)\n",
            "Requirement already satisfied: pillow>=9.1 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (10.2.0)\n",
            "Collecting imageio>=2.33\n",
            "  Downloading imageio-2.35.1-py3-none-any.whl (315 kB)\n",
            "     -------------------------------------- 315.4/315.4 kB 6.5 MB/s eta 0:00:00\n",
            "Collecting tifffile>=2022.8.12\n",
            "  Downloading tifffile-2024.9.20-py3-none-any.whl (228 kB)\n",
            "     -------------------------------------- 228.2/228.2 kB 7.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: packaging>=21 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (24.0)\n",
            "Collecting lazy-loader>=0.4\n",
            "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: tifffile, PyYAML, pydantic-core, opencv-python-headless, lazy-loader, imageio, eval-type-backport, annotated-types, scikit-image, pydantic, albucore, albumentations\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.14\n",
            "    Uninstalling pydantic-1.10.14:\n",
            "      Successfully uninstalled pydantic-1.10.14\n",
            "Successfully installed PyYAML-6.0.2 albucore-0.0.17 albumentations-1.4.17 annotated-types-0.7.0 eval-type-backport-0.2.0 imageio-2.35.1 lazy-loader-0.4 opencv-python-headless-4.10.0.84 pydantic-2.9.2 pydantic-core-2.23.4 scikit-image-0.24.0 tifffile-2024.9.20\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastapi 0.75.0 requires pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2, but you have pydantic 2.9.2 which is incompatible.\n",
            "\n",
            "[notice] A new release of pip available: 22.3 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install opencv-python numpy albumentations scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CfSwJlkqPoMk"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Apply CLAHE preprocessing\n",
        "def apply_clahe(image):\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    if len(image.shape) == 3 and image.shape[2] == 3:\n",
        "        # Apply CLAHE to each channel for color images\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    return clahe.apply(image)\n",
        "\n",
        "# Normalize images between 0 and 1\n",
        "def normalize(image):\n",
        "    image = image.astype(np.float32) / 255.0\n",
        "    return image\n",
        "\n",
        "# Define data augmentation\n",
        "transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomRotate90(p=0.5),\n",
        "    A.ElasticTransform(p=0.5)\n",
        "])\n",
        "\n",
        "# Load and preprocess images\n",
        "def load_images(image_paths):\n",
        "    images = []\n",
        "    for path in image_paths:\n",
        "        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        image = apply_clahe(image)\n",
        "        image = normalize(image)\n",
        "        augmented = transform(image=image)\n",
        "        images.append(augmented['image'])\n",
        "    return np.array(images)\n",
        "\n",
        "# Split dataset into training and test sets (80-20 split)\n",
        "image_paths = glob('Data/Data/*/*.tif')\n",
        "mask_paths = glob('Data/Data/*/*_mask.tif')\n",
        "image_paths = [i for i in image_paths if i not in mask_paths]\n",
        "\n",
        "train_images, test_images, train_masks, test_masks = train_test_split(image_paths, mask_paths, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting segmentation_models_pytorchNote: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "  Downloading segmentation_models_pytorch-0.3.4-py3-none-any.whl (109 kB)\n",
            "     -------------------------------------- 109.5/109.5 kB 1.6 MB/s eta 0:00:00\n",
            "Collecting efficientnet-pytorch==0.7.1\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting huggingface-hub>=0.24.6\n",
            "  Downloading huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\n",
            "     -------------------------------------- 436.4/436.4 kB 4.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pillow in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from segmentation_models_pytorch) (10.2.0)\n",
            "Collecting pretrainedmodels==0.7.4\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "     ---------------------------------------- 58.8/58.8 kB 3.2 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: six in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from segmentation_models_pytorch) (1.16.0)\n",
            "Collecting timm==0.9.7\n",
            "  Downloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n",
            "     ---------------------------------------- 2.2/2.2 MB 10.2 MB/s eta 0:00:00\n",
            "Collecting torchvision>=0.5.0\n",
            "  Downloading torchvision-0.19.1-cp311-cp311-win_amd64.whl (1.3 MB)\n",
            "     ---------------------------------------- 1.3/1.3 MB 11.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: tqdm in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from segmentation_models_pytorch) (4.63.0)\n",
            "Requirement already satisfied: torch in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.2.1)\n",
            "Collecting munch\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from timm==0.9.7->segmentation_models_pytorch) (6.0.2)\n",
            "Collecting safetensors\n",
            "  Downloading safetensors-0.4.5-cp311-none-win_amd64.whl (285 kB)\n",
            "     -------------------------------------- 286.0/286.0 kB 8.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: filelock in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.24.6->segmentation_models_pytorch) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.24.6->segmentation_models_pytorch) (2024.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.24.6->segmentation_models_pytorch) (24.0)\n",
            "Requirement already satisfied: requests in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.24.6->segmentation_models_pytorch) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.24.6->segmentation_models_pytorch) (4.10.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.26.3)\n",
            "Collecting torch\n",
            "  Downloading torch-2.4.1-cp311-cp311-win_amd64.whl (199.4 MB)\n",
            "     -------------------------------------- 199.4/199.4 MB 1.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: sympy in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->segmentation_models_pytorch) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.24.6->segmentation_models_pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.24.6->segmentation_models_pytorch) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.24.6->segmentation_models_pytorch) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.24.6->segmentation_models_pytorch) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py): started\n",
            "  Building wheel for efficientnet-pytorch (setup.py): finished with status 'done'\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16464 sha256=74f6757730ea847ede070fe3d73db3d3b490864d6d82ec8d2d80c503512503cf\n",
            "  Stored in directory: c:\\users\\karan\\appdata\\local\\pip\\cache\\wheels\\5b\\40\\c3\\afeb111ff7a5abde37eca97b3b447651c6de127933eef6941f\n",
            "  Building wheel for pretrainedmodels (setup.py): started\n",
            "  Building wheel for pretrainedmodels (setup.py): finished with status 'done'\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=61017 sha256=4f77da9ef7b3049417daf437215845fe6770cedf2286184d4f6ca25fd639f426\n",
            "  Stored in directory: c:\\users\\karan\\appdata\\local\\pip\\cache\\wheels\\e7\\4c\\26\\38e3318a78a5d2e211684be20aca0bd17db41fd5cd727b7c89\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: safetensors, munch, torch, huggingface-hub, torchvision, efficientnet-pytorch, timm, pretrainedmodels, segmentation_models_pytorch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1\n",
            "    Uninstalling torch-2.2.1:\n",
            "      Successfully uninstalled torch-2.2.1\n",
            "Successfully installed efficientnet-pytorch-0.7.1 huggingface-hub-0.25.1 munch-4.0.0 pretrainedmodels-0.7.4 safetensors-0.4.5 segmentation_models_pytorch-0.3.4 timm-0.9.7 torch-2.4.1 torchvision-0.19.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install -U segmentation_models_pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4BeSUJFaP2Ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UnetPlusPlus(\n",
            "  (encoder): ResNetEncoder(\n",
            "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (4): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (5): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): UnetPlusPlusDecoder(\n",
            "    (center): Identity()\n",
            "    (blocks): ModuleDict(\n",
            "      (x_0_0): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "      )\n",
            "      (x_0_1): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "      )\n",
            "      (x_1_1): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "      )\n",
            "      (x_0_2): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "      )\n",
            "      (x_1_2): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "      )\n",
            "      (x_2_2): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "      )\n",
            "      (x_0_3): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "      )\n",
            "      (x_1_3): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "      )\n",
            "      (x_2_3): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "      )\n",
            "      (x_3_3): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "      )\n",
            "      (x_0_4): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (segmentation_head): SegmentationHead(\n",
            "    (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Identity()\n",
            "    (2): Activation(\n",
            "      (activation): Identity()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# Define U-Net++ model with ResNet backbone\n",
        "unet_plus_plus_model = smp.UnetPlusPlus(\n",
        "    encoder_name=\"resnet34\",        # Use a pretrained ResNet34 encoder\n",
        "    encoder_weights=\"imagenet\",     # Use imagenet pretrained weights\n",
        "    in_channels=1,                  # For grayscale MRI images\n",
        "    classes=1,                      # Output is binary segmentation (0 or 1 for metastasis)\n",
        "    activation=None                 # Use no activation as we will apply Sigmoid/Softmax later\n",
        ")\n",
        "\n",
        "# Summary of the model\n",
        "print(unet_plus_plus_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.0.5)Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Requirement already satisfied: absl-py in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras) (2.1.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras) (1.26.3)\n",
            "Requirement already satisfied: rich in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras) (13.7.1)\n",
            "Requirement already satisfied: namex in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras) (0.0.7)\n",
            "Requirement already satisfied: h5py in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras) (3.10.0)\n",
            "Requirement already satisfied: dm-tree in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras) (0.1.8)\n",
            "Requirement already satisfied: ml-dtypes in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras) (0.3.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras) (2.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.16.1)\n",
            "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.16.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.7)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (65.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.0.5)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
            "Requirement already satisfied: dm-tree in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: setuptools in c:\\users\\karan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (65.5.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3_zGTEXP7bj"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, UpSampling2D, Concatenate, Activation, Multiply, MaxPooling2D\n",
        "\n",
        "def attention_gate(x, g, inter_channel):\n",
        "    # Downsample x\n",
        "    theta_x = Conv2D(inter_channel, (2, 2), strides=(2, 2), padding='same')(x)\n",
        "    \n",
        "    # Ensure g is downsampled to match the shape of theta_x\n",
        "    phi_g = Conv2D(inter_channel, (1, 1), padding='same')(g)\n",
        "    # Add downsampling to g to match theta_x dimensions\n",
        "    phi_g = MaxPooling2D(pool_size=(2, 2))(phi_g)\n",
        "\n",
        "    # Add and apply activation\n",
        "    add = Activation('relu')(theta_x + phi_g)\n",
        "    psi = Conv2D(1, (1, 1), padding='same')(add)\n",
        "    sigmoid = Activation('sigmoid')(psi)\n",
        "    \n",
        "    # Multiply the original input with the attention weights\n",
        "    x = Multiply()([x, sigmoid])\n",
        "    return x\n",
        "\n",
        "def attention_unet(input_shape=(256, 256, 1)):\n",
        "    inputs = Input(input_shape)\n",
        "    \n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    \n",
        "    # Assuming you want to maintain a reference to the encoder output\n",
        "    attention1 = attention_gate(conv1, conv1, 64)\n",
        "\n",
        "    # Final output layer, adjust as needed for your application\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(attention1)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "model = attention_unet()\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('unet.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RAdjO3yP_MD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import cv2  # Ensure you have cv2 to load images\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, images, masks):\n",
        "        self.images = images  # Expecting file paths\n",
        "        self.masks = masks    # Expecting file paths\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load the image and mask\n",
        "        image = cv2.imread(self.images[idx], cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
        "        mask = cv2.imread(self.masks[idx], cv2.IMREAD_GRAYSCALE)    # Load as grayscale\n",
        "        \n",
        "        if image is None or mask is None:\n",
        "            raise ValueError(f\"Image or mask at index {idx} could not be loaded.\")\n",
        "\n",
        "        # Ensure they are numpy arrays\n",
        "        image = image.astype(np.float32)  # Ensure it's float32\n",
        "        mask = mask.astype(np.float32)    # Ensure it's float32\n",
        "\n",
        "        # Add a channel dimension\n",
        "        image = np.expand_dims(image, axis=0)  # shape: (1, height, width)\n",
        "        mask = np.expand_dims(mask, axis=0)    # shape: (1, height, width)\n",
        "\n",
        "        return torch.tensor(image, dtype=torch.float32), torch.tensor(mask, dtype=torch.float32)\n",
        "\n",
        "\n",
        "\n",
        "# DICE Score Calculation\n",
        "def dice_loss(pred, target, smooth=1e-6):\n",
        "    pred = torch.sigmoid(pred)\n",
        "    intersection = (pred * target).sum()\n",
        "    return 1 - (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, train_loader, test_loader, epochs=20, lr=1e-4):\n",
        "    optimizer = Adam(model.parameters(), lr=lr)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for images, masks in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = dice_loss(outputs, masks)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f'Epoch {epoch}/{epochs}, Loss: {loss.item()}')\n",
        "\n",
        "# Prepare data loaders\n",
        "train_dataset = MRIDataset(train_images, train_masks)\n",
        "test_dataset = MRIDataset(test_images, test_masks)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8)\n",
        "\n",
        "# Train Nested U-Net\n",
        "train_model(unet_plus_plus_model, train_loader, test_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(unet_plus_plus_model,'unet_model.pth')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
